# -*- coding: utf-8 -*-
"""
Worker em Background para sincroniza√ß√£o com API Malga
Roda periodicamente (a cada 1 minuto) e mant√©m dados agregados no SQLite
"""

import requests
import pandas as pd
import json
import time
import logging
from datetime import datetime, timedelta
from apscheduler.schedulers.blocking import BlockingScheduler
from worker.config import *
from worker.malga_database import MalgaDatabase

# --- CONFIGURA√á√ÉO DE LOGGING ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(LOG_FILE),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# --- CLASSE PRINCIPAL DO WORKER ---

class MalgaWorker:
    """Worker para sincroniza√ß√£o peri√≥dica com API Malga"""
    
    def __init__(self):
        self.db = MalgaDatabase()
        self.headers = None
    
    def authenticate(self):
        """Autentica na API Malga"""
        self.headers = {
            "X-Client-Id": MALGA_CLIENT_ID,
            "X-Api-Key": MALGA_CLIENT_SECRET,
            "Content-Type": "application/json",
            "Accept": "application/json"
        }
        
        try:
            logger.info(f"üîê Autenticando com Client-Id: {MALGA_CLIENT_ID[:20]}...")
            response = requests.get(f"{API_ENDPOINT}?limit=1", 
                                    headers=self.headers, 
                                    timeout=API_TIMEOUT)
            
            if response.status_code == 200:
                logger.info("‚úÖ Autentica√ß√£o bem-sucedida")
                return True
            elif response.status_code == 401:
                logger.error(f"‚ùå Credenciais inv√°lidas (401)")
                logger.error(f"   Client-Id: {MALGA_CLIENT_ID}")
                return False
            elif response.status_code == 403:
                logger.error(f"‚ùå Acesso negado (403)")
                return False
            else:
                logger.error(f"‚ùå Erro de autentica√ß√£o: HTTP {response.status_code}")
                logger.error(f"   Resposta: {response.text[:200]}")
                return False
        except Exception as e:
            logger.error(f"‚ùå Erro ao autenticar: {e}")
            return False
    
    def fetch_new_transactions(self, last_sync_date):
        """Busca transa√ß√µes novas desde √∫ltima sincroniza√ß√£o"""
        if not self.authenticate():
            return []
        
        all_transactions = []
        page = 1
        total_collected = 0
        
        # Define estrat√©gia de busca
        if last_sync_date:
            # Sincroniza√ß√£o incremental - busca apenas novas
            start_date = last_sync_date
            # Usa formato completo com hora para precis√£o
            start_date_str = start_date.strftime('%Y-%m-%dT%H:%M:%S')
            logger.info(f"üîÑ Sincroniza√ß√£o incremental desde {start_date_str}...")
            use_date_filter = True
        else:
            # Primeira sincroniza√ß√£o - busca TUDO
            logger.info(f"üîç PRIMEIRA SINCRONIZA√á√ÉO - Buscando TODAS as transa√ß√µes...")
            use_date_filter = False
            start_date_str = None
        
        logger.info(f"üéØ LIMITE CONFIGURADO: {MAX_TRANSACTIONS_PER_SYNC} transa√ß√µes")
        
        while page <= MAX_API_PAGES:
            # Define par√¢metros baseado na estrat√©gia
            if use_date_filter and start_date_str:
                params = {
                    "limit": 100,
                    "page": page,
                    "created.gt": start_date_str,  # API s√≥ aceita .gt (maior que), n√£o .gte
                    "sort": "DESC"
                }
            else:
                params = {
                    "limit": 100,
                    "page": page,
                    "sort": "DESC"
                }
            
            try:
                logger.info(f"üì° P√°gina {page}...")
                response = requests.get(API_ENDPOINT, 
                                        headers=self.headers, 
                                        params=params, 
                                        timeout=API_TIMEOUT)
                
                if response.status_code == 200:
                    data = response.json()
                    items = data.get('items', [])
                    
                    if not items:
                        logger.info(f"üì≠ P√°gina {page} sem itens - fim da busca")
                        break
                    
                    # Calcula quanto espa√ßo ainda temos dispon√≠vel
                    remaining_space = MAX_TRANSACTIONS_PER_SYNC - total_collected
                    
                    # Se o limite j√° foi atingido, para
                    if remaining_space <= 0:
                        logger.warning(f"ÔøΩ LIMITE ATINGIDO: {total_collected} transa√ß√µes coletadas")
                        break
                    
                    # Se esta p√°gina ultrapassaria o limite, pega s√≥ o necess√°rio
                    if len(items) > remaining_space:
                        items = items[:remaining_space]
                        logger.info(f"‚úÇÔ∏è P√°gina {page}: Cortando para {remaining_space} transa√ß√µes (limite atingido)")
                    
                    all_transactions.extend(items)
                    total_collected = len(all_transactions)
                    
                    logger.info(f"üìÑ P√°gina {page}: {len(items)} transa√ß√µes | Total acumulado: {total_collected}/{MAX_TRANSACTIONS_PER_SYNC}")
                    
                    # Se atingiu o limite exato, para
                    if total_collected >= MAX_TRANSACTIONS_PER_SYNC:
                        logger.warning(f"üõë LIMITE ATINGIDO: {total_collected} transa√ß√µes coletadas")
                        break
                    
                    # Se retornou menos que 100, n√£o h√° mais p√°ginas
                    if len(items) < 100:
                        logger.info(f"‚úÖ √öltima p√°gina alcan√ßada (menos de 100 items)")
                        break
                    
                    page += 1
                    
                    # Rate limiting - evita sobrecarregar API
                    time.sleep(0.5)
                    
                else:
                    logger.error(f"‚ùå HTTP {response.status_code} - {response.text[:200]}")
                    break
                    
            except Exception as e:
                logger.error(f"‚ùå Erro na p√°gina {page}: {e}")
                break
        
        logger.info(f"‚úÖ Total de {len(all_transactions)} transa√ß√µes coletadas")
        logger.info(f"üìä P√°ginas processadas: {page - 1}")
        return all_transactions
    
    def process_transactions(self, transactions):
        """Processa e transforma dados brutos da API"""
        if not transactions:
            return pd.DataFrame()
        
        processed_data = []
        
        for tx in transactions:
            try:
                # Extrai dados relevantes
                processed = {
                    'id': tx.get('id'),
                    'created_at': tx.get('createdAt'),
                    'amount': tx.get('amount', 0) / 100,  # Converte centavos para reais
                    'status': tx.get('status'),
                    'payment_method': tx.get('paymentMethod', {}).get('paymentType'),
                    'card_brand': tx.get('paymentMethod', {}).get('card', {}).get('brand'),
                    'description': tx.get('description'),
                    'declined_code': tx.get('declinedCode'),
                    'network_denied_reason': tx.get('networkDeniedReason'),
                    'network_denied_message': tx.get('networkDeniedMessage'),
                    'retryable': 1 if tx.get('retryable') else 0,
                    'raw_json': json.dumps(tx)
                }
                
                processed_data.append(processed)
                
            except Exception as e:
                logger.error(f"‚ùå Erro ao processar transa√ß√£o {tx.get('id')}: {e}")
                continue
        
        df = pd.DataFrame(processed_data)
        
        # Converte datas
        if not df.empty and 'created_at' in df.columns:
            df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce')
        
        logger.info(f"‚úÖ {len(df)} transa√ß√µes processadas")
        return df
    
    def sync_and_aggregate(self):
        """Executa sincroniza√ß√£o completa e agrega√ß√µes"""
        logger.info("=" * 60)
        logger.info("üöÄ Iniciando sincroniza√ß√£o...")
        logger.info("=" * 60)
        
        try:
            # Verifica √∫ltima sincroniza√ß√£o
            sync_info = self.db.get_last_sync_info()
            
            if sync_info:
                last_sync = sync_info[1]
                last_transaction_date_str = sync_info[2]
                logger.info(f"üìÖ √öltima sincroniza√ß√£o: {last_sync}")
                
                # Converte string para datetime se necess√°rio
                if last_transaction_date_str:
                    if isinstance(last_transaction_date_str, str):
                        last_transaction_date = pd.to_datetime(last_transaction_date_str, format='mixed')
                    else:
                        last_transaction_date = last_transaction_date_str
                else:
                    last_transaction_date = None
            else:
                last_transaction_date = None
                logger.info("üìÖ Primeira sincroniza√ß√£o")
            
            # Busca novas transa√ß√µes
            transactions = self.fetch_new_transactions(last_transaction_date)
            
            if transactions:
                # Processa transa√ß√µes
                df = self.process_transactions(transactions)
                
                if not df.empty:
                    # Insere no banco
                    logger.info("üíæ Inserindo transa√ß√µes no banco...")
                    inserted_count = self.db.insert_transactions(df)
                    
                    if inserted_count > 0:
                        logger.info(f"‚úÖ {inserted_count} transa√ß√µes NOVAS inseridas (de {len(df)} coletadas)")
                    else:
                        logger.info(f"‚ÑπÔ∏è Nenhuma transa√ß√£o nova (todas j√° existiam no banco)")
                    
                    # Pega data mais recente e converte para string
                    newest_date_str = pd.to_datetime(df['created_at'].max()).strftime('%Y-%m-%d %H:%M:%S')
                    
                    # Agrega dados
                    logger.info("üìä Iniciando agrega√ß√µes...")
                    self.db.aggregate_by_minute()
                    self.db.aggregate_by_hour()
                    self.db.aggregate_by_day()
                    
                    # Atualiza controle
                    self.db.update_sync_control(
                        last_transaction_date=newest_date_str,
                        total_synced=len(df)
                    )
                    
                    logger.info(f"‚úÖ Sincroniza√ß√£o conclu√≠da: {len(df)} transa√ß√µes")
                else:
                    logger.info("‚ÑπÔ∏è Nenhuma transa√ß√£o nova encontrada")
                    self.db.update_sync_control()
            else:
                logger.info("‚ÑπÔ∏è Nenhuma transa√ß√£o nova para processar")
                self.db.update_sync_control()
            
            # Mostra estat√≠sticas
            stats = self.db.get_database_stats()
            logger.info("üìà Estat√≠sticas do banco:")
            logger.info(f"   - Total de transa√ß√µes: {stats['total_transactions']}")
            logger.info(f"   - M√©tricas por minuto: {stats['metrics_by_minute']}")
            logger.info(f"   - M√©tricas por hora: {stats['metrics_by_hour']}")
            logger.info(f"   - M√©tricas por dia: {stats['metrics_by_day']}")
            
        except Exception as e:
            logger.error(f"‚ùå Erro durante sincroniza√ß√£o: {e}")
            self.db.update_sync_control(error=str(e))
        
        logger.info("=" * 60)
        logger.info(f"‚è∞ Pr√≥xima sincroniza√ß√£o em {SYNC_INTERVAL_MINUTES} minuto(s)")
        logger.info("=" * 60)

# --- FUN√á√ïES PRINCIPAIS ---

def initialize_system():
    """Inicializa sistema na primeira execu√ß√£o"""
    logger.info("üîß Inicializando sistema...")
    db = MalgaDatabase()
    db.init_database()
    logger.info("‚úÖ Sistema inicializado com sucesso!")

def start_worker():
    """Inicia worker em modo cont√≠nuo"""
    logger.info("=" * 60)
    logger.info("üöÄ MALGA WORKER - INICIANDO")
    logger.info("=" * 60)
    logger.info(f"‚è∞ Intervalo de sincroniza√ß√£o: {SYNC_INTERVAL_MINUTES} minuto(s)")
    logger.info(f"üíæ Banco de dados: {DB_PATH}")
    logger.info("=" * 60)
    
    # Inicializa banco se necess√°rio
    initialize_system()
    
    # Cria inst√¢ncia do worker
    worker = MalgaWorker()
    
    # Executa primeira sincroniza√ß√£o imediatamente
    logger.info("üîÑ Executando primeira sincroniza√ß√£o...")
    worker.sync_and_aggregate()
    
    # Configura scheduler
    scheduler = BlockingScheduler()
    scheduler.add_job(
        worker.sync_and_aggregate,
        'interval',
        minutes=SYNC_INTERVAL_MINUTES,
        id='malga_sync',
        name='Sincroniza√ß√£o Malga',
        replace_existing=True
    )
    
    logger.info("‚úÖ Worker configurado e rodando!")
    logger.info("‚ö†Ô∏è Pressione Ctrl+C para parar")
    
    try:
        scheduler.start()
    except (KeyboardInterrupt, SystemExit):
        logger.info("‚èπÔ∏è Worker finalizado pelo usu√°rio")

if __name__ == "__main__":
    start_worker()
